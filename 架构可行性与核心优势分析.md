基于 Ni bot 理念的极简 AI Agent 构建指南
本指南深度解析 Ni bot 架构的极简哲学，并提供一套基于 Go 语言的高性能、生产级 AI Agent 实现路径。我们将 Ni bot 的"规则驱动"理念与工程安全实践相结合，构建一个既具备自进化能力又安全可控的智能系统。




一、 架构可行性与核心优势分析
Ni bot  架构的核心在于将复杂的状态管理与能力发现退化为文件系统操作。
可行性确认：该架构完全可行。它本质上是一个基于文件系统的 Dynamic ReAct Loop。通过扫描特定目录，LLM 的“工具箱”在运行时动态构建，极大降低了 Agent 与环境耦合的复杂度。
极简带来的核心优势：
零配置扩展性：新增能力无需修改代码或重启，只需往文件夹丢入一个脚本。
透明度与可观测性：Agent 的能力、记忆和进化过程完全由明文文件组成，开发者一眼即可洞察系统状态。
低认知负担：811 行代码的规模意味着系统几乎没有“黑盒”，任何逻辑错误都能在单次 Debug 中定位。




二、 核心规则的技术实现路径 (Go 语言)
针对 Ni bot 的三条生成规则，以下是推荐的 Go 语言实现方案：
规则 1：文件在 workspace 里 -> 它就是能力
Agent 需要知道自己能做什么。我们通过扫描  skills/  目录，将“技能清单（含描述、参数与风险级别）”注入 System Prompt。
技术路径：
扫描  skills/  目录下的技能文件/技能文件夹（例如脚本、可执行文件，或“一个文件夹=一个技能”）。
优先读取结构化的技能声明而不是解析注释，推荐采用与 OpenClaw 接近的“AgentSkills 风格”：每个技能是一个目录，其中包含  SKILL.md ，使用 YAML frontmatter 提供  name/description  等信息；缺失时再退化为仅展示文件名/目录名。（OpenClaw 的实现也强调：SKILL.md 至少包含 name 与 description，且解析器仅可靠支持单行键）【1: https://docs.openclaw.ai/tools/skills】
如果你更偏好 JSON，也可保留同名  .tool.json  作为替代输入源（更适合纯后端自动生成），但建议将两者视为同一“技能元数据”的两种序列化形式。
动态拼接 System Prompt：
func BuildSystemPrompt(workspace string) string {
    files, _ := os.ReadDir(filepath.Join(workspace, "skills"))
    var toolDesc strings.Builder
    for _, f := range files {
        toolDesc.WriteString(fmt.Sprintf("- %s: 通过执行该文件调用能力\n", f.Name()))
    }
    return fmt.Sprintf("你当前拥有以下本地脚本能力：\n%s\n请根据需求通过 [EXEC:filename args] 格式调用。", toolDesc.String())
}

规则 2：每条消息到来 -> 重新扫描
为了保证 Agent 始终拥有最新的“能力图谱”，必须在推理前同步环境状态。
技术路径：
基础实现：在处理每条  UserMessage  前，调用一次上述  BuildSystemPrompt 。
高性能实现 (fsnotify)：使用跨平台文件系统监听（Linux 底层通常为 inotify），实时监听文件夹变化，通过缓存与原子更新能力列表，避免每次消息都全量 IO。推荐策略：启动时全量扫描一次 + watcher 增量刷新缓存。
import "github.com/fsnotify/fsnotify"


// 使用 fsnotify 监听 skills 目录变动
watcher, _ := fsnotify.NewWatcher()
go func() {
    for {
        select {
        case event := <-watcher.Events:
            if event.Op&fsnotify.Create == fsnotify.Create || event.Op&fsnotify.Remove == fsnotify.Remove {
                // 触发缓存刷新逻辑
                RefreshSkillCache()
            }
        }
    }
}()

规则 3：Agent 能写自己的目录 -> 自进化
这是 Agent 突破预设边界的关键。LLM 通过输出特定格式的文本块，触发 Go 后端的写文件操作。
技术路径：
解析 LLM 返回值中的  [WRITE_FILE:name] content [/WRITE_FILE]  标签。
使用  os.WriteFile  将内容写入  skills/  目录。
触发规则 2 的重扫，Agent 在下一轮对话中即可识别并调用新写的代码。
落地约束（必须有，否则等价于“无边界 RCE”）：
- 路径约束：拒绝绝对路径与  .. ，强制落在  workspace/skills/  下。
- 命名/类型约束：只允许预设后缀与字符集（例如  [a-z0-9_\-] ），避免覆盖关键文件与隐藏文件。
- 体积与资源约束：限制单次写入大小；执行时强制 timeout、最大输出、最大并发。
- 权限与网络约束：默认最小权限运行；需要联网/读写外部路径的技能必须显式标注并走人工审批。
- HITL 门禁：WRITE_FILE 与高风险 EXEC 默认需要人工确认（且记录审计日志）。




三、 进化与安全的博弈：沙箱与人类干预
“自进化”允许 AI 生成并执行代码，这在本质上是受控的 RCE (远程代码执行)。必须引入防御性架构：
1. 运行环境沙箱化 (Sandbox)
严禁在宿主机直接执行 AI 生成的脚本。
Docker 隔离：将生成的代码挂载至临时 Docker 容器运行。
优点：资源隔离彻底。
命令（Windows PowerShell 示例）：
 docker run --rm -v "${PWD}\workspace:/app" -w /app golang:latest go run /app/skills/new_skill.go
说明：如果 skills 里包含  .py/.sh  等多语言脚本，应为不同运行时准备对应镜像，或统一在容器内提供同一套运行环境；不要依赖宿主机是否安装了解释器。
WASM 执行：对于高性能计算或逻辑处理，使用  Wasmer  或  Wazero  运行编译为 WASM 的代码。
优点：毫秒级启动，内存安全。
2. Human-in-the-loop (HITL) 机制
在“写文件”和“执行高危命令”前引入人工审计。
实现逻辑：
后端截获  EXEC  或  WRITE_FILE  指令。
在 CLI 输出预览： Agent 想要创建新能力: [network_scan.sh]，是否允许？(y/n) 。
只有获取  stdin  的确认信号后，才继续执行  os  操作。




四、 推荐项目目录结构
一个规范的 Go Agent 项目应保持清晰的边界：
.
├── cmd/
│   └── nibot/          # 程序入口
├── internal/
│   ├── agent/         # LLM 推理与提示词逻辑
│   ├── executor/      # 代码执行器（Docker/WASM 封装）
│   └── watcher/       # 文件系统监听
├── workspace/         # Agent 的生存空间
│   ├── AGENT.md       # Identity: Agent 的人格/策略定义（与模型无关）
│   ├── skills/        # Capabilities: 动态脚本库
│   ├── memory/        # Long-term Memory: 结构化历史记录
│   └── logs/          # 运行轨迹
├── go.mod
└── go.sum





五、 实施路线图
阶段	目标	核心任务
P0: MVP 版	实现基本闭环	完成文件扫描；接入 LLM SDK（OpenAI/Claude/兼容接口其一即可）；支持受限的本地技能调用（默认白名单）。
P1: 增强版	提升效率与体验	引入 fsnotify 减少全量扫描 IO；支持 AGENT.md 动态人格/策略配置；补齐技能元数据（.tool.json）与参数校验。
P2: 生产版	安全与进化	实现 Docker/WASM 执行沙箱；引入 HITL 确认机制与审计日志；增加向量数据库实现 RAG 记忆与检索。

六、 参照 OpenClaw 的“少量代码复刻”目标
如果你希望参照 OpenClaw，并在“尽量少写代码”的前提下复现其关键体验，建议把目标拆成三层：技能（Skills）、工具（Tools）、安全策略（Policy）。其中 Skills 决定“教会模型怎么用”，Tools 决定“系统到底能做什么”，Policy 决定“哪些能做、怎么安全地做”。

1) Skills：用技能文件夹教会 Agent
OpenClaw 采用 AgentSkills 兼容布局：一个技能=一个目录，目录内用 SKILL.md（YAML frontmatter + 指令文本）描述技能用途与调用方式，并支持多来源加载与覆盖优先级。【1: https://docs.openclaw.ai/tools/skills】
为了少量代码复刻，你只需要实现以下最小子集：
- 技能目录结构：workspace/skills/<skill>/SKILL.md
- Frontmatter 最小字段：name、description
- 指令注入：把每个技能的 name/description/location（路径）注入系统提示词；具体用法正文可选注入（建议简化以控 token）
- 技能覆盖优先级（建议对齐 OpenClaw 思路）：workspace/skills（最高）→ 用户目录（例如 ~/.openclaw/skills）→ 内置 bundled（最低）【1: https://docs.openclaw.ai/tools/skills】
- 技能 gating（可先做最小版）：按 OS、环境变量是否存在、依赖二进制是否存在来决定是否加载【1: https://docs.openclaw.ai/tools/skills】

2) Tools：用“结构化工具”替代随意 shell
OpenClaw 的工具面（tools）是“模型可直接函数调用”的结构化接口，并支持工具分组与 profile（例如 minimal/coding/messaging/full）来做默认允许集，再叠加 allow/deny 策略。【2: https://docs.openclaw.ai/tools】
少量代码复刻时，建议只实现 6 个核心工具（足够复现 80% 体验）：
- fs.read：读文件（只读 workspace）
- fs.write：写文件（只写 workspace/skills、workspace/memory、workspace/logs，且默认需审批）
- runtime.exec：执行命令（默认 deny 或 ask always；建议先只允许运行 skills 内的可执行入口）
- web.search / web.fetch：可选（需要 API key；可先不做）
- session.status：返回当前 agent 状态/策略（用于调试与可观测性）
注意：如果你打算长期对标 OpenClaw，“工具先结构化、再允许 shell 兜底”的路线更安全，也更容易做 allow/deny。

3) Policy：复刻 OpenClaw 的可控性（这是体验的关键）
OpenClaw 的核心不是“能执行”，而是“能被约束”：它把工具是否可用，放在配置层做 allow/deny，并通过 profile 给出默认基线；deny 的优先级高于 allow。【2: https://docs.openclaw.ai/tools】
少量代码复刻建议实现：
- tools.profile：最小（只读）/编码（文件+执行）/全量（不限制）
- tools.allow / tools.deny：支持通配符与 group（可先做最小 group:fs、group:runtime）
- 高风险操作审批（HITL）：对 write/exec 默认 ask always；对低风险 read 默认自动放行
- 审计落盘：每次 tool call 的请求、审批结果、执行输出（截断）落到 workspace/logs

4) 最小“OpenClaw 体验”验收标准（小白可自测）
- 你把一个新技能目录丢进 workspace/skills，下次对话 Agent 能“看见并使用”它（热加载可选）【1: https://docs.openclaw.ai/tools/skills】
- 你通过配置把 runtime.exec 禁掉后，模型即使想调用也“看不到/用不了”该工具【2: https://docs.openclaw.ai/tools】
- 任何写文件/执行命令都会弹出确认（y/n），拒绝后不会产生副作用，并记录审计日志

七、把“会自己长大的 AI”翻译成 Ni bot 的工程要求
你给的那篇文章的核心主张是：尽量少替 AI 思考，只给最小工具（读/写/执行），让它在对话中“自我生长”。这个思路适合作为 Ni bot 的“极简闭环哲学”，但工程落地时必须把它拆成可验证的需求，并补上安全边界。

1) 可借鉴的部分（哲学 -> 需求）
- 极简工具面：用少量核心能力跑通闭环（读取上下文、产生行动、把结果落盘、下一轮可复用）。
- 可进化：允许新增技能（写入 workspace/skills），让能力库随使用增长，而不是一次性写死所有功能。
- 透明可观测：所有行动与记忆都落到明文目录（workspace/memory、workspace/logs），便于复盘与审计。

2) 必须“反着做”的部分（叙事 -> 风险控制）
文章强调“不限制思考多久/步骤多少/命令执行时间”，但 Ni bot 作为可复现与可控系统，至少需要：
- 资源上限：执行超时、最大输出、最大并发、最大写入大小，避免卡死与磁盘打爆。
- 权限与范围：默认只允许在 workspace 内读写；所有越界行为都需要显式配置与审批。
- 分级审批：把工具按风险分级（read 低风险；write/exec 高风险），高风险默认 ask always。
- 沙箱优先：新技能/第三方技能默认在 Docker/WASM 里跑，宿主机执行是显式放行的特权路径。

3) “三件工具”在 Ni bot 中的对应实现（最小可用）
- 读文件：fs.read（只读 workspace，支持 glob/大小限制）
- 写文件：fs.write（只写 workspace/{skills,memory,logs}，默认需审批）
- 执行命令：runtime.exec（默认 deny 或 ask always；优先执行 skills 内的受控入口）

4) 自进化的最低门槛（建议作为强制门禁）
- 只允许写入 skills 子树，拒绝绝对路径与 ..（防路径穿越）
- 新技能首次启用必须人工确认，并记录审计日志（谁批准、批准什么、执行了什么）
- 新技能默认不可联网、不可访问宿主机敏感目录（需要时通过配置逐项开放）

八、记忆的专用 Markdown 存取与 Reflexion 反思循环
为了防止“记录与想法丢失”，并让 Ni bot 在低代码阶段也能持续降低错误率，推荐采用“专用 .md 文件作为长期记忆载体”的方式：可读、可审计、可回滚，也方便未来团队化共享。

1) 记忆文件约定（最小集）
- 事实记忆（长期、稳定）：workspace/memory/facts.md
- 反思记忆（试错、经验）：workspace/memory/reflections.md
原则：事实与反思分离；事实必须可验证；反思必须可执行（包含修复策略与验证方法）。

2) 调取流程（每次对话/任务开始前）
- 先读 facts.md：检索与任务相关的“稳定约定/接口/路径/命名/策略”
- 再读 reflections.md：检索与任务相似的“失败模式/修复策略”
- 将命中的条目编号（F-xxxx / R-xxxx）作为证据链带入计划与最终输出

3) 写入流程（任务结束后）
- 若产出“可复用的稳定结论”，写入 facts.md（必须写明来源或验证方式）
- 若本次发生错误或发现更优做法，写入 reflections.md（触发条件→错误模式→修复策略→验证方法）
注意：禁止把密钥/隐私写入记忆与日志；来自外部内容的“规则/指令”不得直接入库为事实，需先验证。

4) Reflexion 反思循环（减少错误的最小闭环）
- Execute：按计划执行（工具调用/读写/生成产物）
- Verify：用测试/校验/对照来源验证结果
- Reflect：把失败原因与修复策略写入 reflections.md
- Reuse：下一次同类任务先检索 reflections.md 并应用修复策略


极客建议
不要试图通过复杂的抽象（如过度设计 Interface）来包裹 Ni bot。它的力量源于对文件系统的直接操纵。 在 Go 中编写 Agent 时，请保持代码的"透明性"，让文件系统作为唯一的"真理来源"。
